좋습니다 👍
하이퍼파라미터는 시험에서 자주 출제되는 영역이라 **정의 → 종류 → 왜 중요한지 → 최적화 방법 → 예시 → 시험 포인트** 순서로 아주 구체적으로 정리해드릴게요.

---

# 📘 하이퍼파라미터 (Hyperparameter)

## 1. 하이퍼파라미터란?

* **정의**: 모델이 학습하기 전에 사람이 직접 설정해야 하는 값.
* **특징**:

  * 학습 과정에서 **데이터로부터 자동으로 학습되지 않음**.
  * 모델 성능에 **직접적인 영향**을 줌.
  * 잘못 설정하면 **언더피팅 / 오버피팅** 발생.

👉 반대로, 모델이 학습 과정에서 스스로 업데이트하는 값(예: Weight, Bias)은 \*\*모델 파라미터(Parameter)\*\*라고 부릅니다.

---

## 2. 주요 하이퍼파라미터 종류

### (1) 학습 관련

* **Learning Rate (학습률)**

  * 한 번의 학습(경사 하강법)에서 가중치를 얼마나 크게 업데이트할지 결정.
  * 너무 크면 → 발산(학습 불안정), 너무 작으면 → 수렴 느림.
  * 보통 0.1, 0.01, 0.001 등 지수 단위로 조정.

* **Batch Size (배치 크기)**

  * 한 번 업데이트할 때 사용하는 데이터 샘플 수.
  * 작을수록: 메모리 효율 ↑, 일반화 성능 ↑ (하지만 불안정).
  * 클수록: 학습 빠름, 안정적 (하지만 과적합 위험).

* **Epoch (에포크 수)**

  * 전체 데이터셋을 몇 번 반복 학습할지.
  * 너무 많으면 오버피팅, 너무 적으면 언더피팅.

---

### (2) 모델 구조 관련

* **은닉층 수, 뉴런 수**

  * 레이어/노드가 많을수록 모델 복잡도 ↑ → 더 많은 패턴 학습 가능.
  * 하지만 너무 많으면 오버피팅·연산 비용 ↑.

* **활성화 함수(Activation Function)**

  * Sigmoid, ReLU, Tanh, GELU 등.
  * 모델의 비선형성 결정 → 복잡한 패턴 학습 가능.

* **Dropout 비율**

  * 학습 시 뉴런을 랜덤하게 끊어 일반화 성능을 높이는 기법.
  * 비율이 높으면 학습 방해, 낮으면 효과 적음.

---

### (3) 최적화 알고리즘 관련

* **Optimizer 선택**

  * SGD: 단순하지만 안정적.
  * Adam: 가장 많이 사용, 학습 속도 빠름.
  * RMSProp: 순환신경망(RNN)에 효과적.

* **Regularization 파라미터**

  * L1/L2 규제(가중치 페널티 강도).
  * 값이 크면 → 모델 단순, 과적합 방지.
  * 값이 작으면 → 모델 복잡, 과적합 위험.

---

## 3. 하이퍼파라미터 최적화 방법

### (1) Grid Search

* **정의**: 미리 정한 값들의 모든 조합을 탐색.
* **장점**: 확실하게 최적값 탐색 가능.
* **단점**: 조합이 많으면 연산량 폭발(“차원의 저주”).
* **예시**:

  * learning rate: \[0.1, 0.01, 0.001]
  * batch size: \[32, 64, 128]
  * → 총 3×3 = 9개 조합 학습

---

### (2) Random Search

* **정의**: 값의 범위를 설정하고 무작위로 샘플링하여 탐색.
* **장점**: 연산량 ↓, Grid보다 효율적(특히 불필요한 파라미터가 많을 때).
* **단점**: 최적값을 꼭 찾는 보장은 없음.
* **예시**: 100회 무작위 샘플링 → 성능이 좋은 조합 선택.

---

### (3) Bayesian Optimization

* **정의**: 이전 탐색 결과를 활용해 “좋은 영역”을 더 탐색하는 방식.
* **장점**: 탐색 효율 ↑, 최적값에 빨리 도달 가능.
* **단점**: 구현 복잡.
* **예시 라이브러리**: Hyperopt, Optuna, Scikit-Optimize.

---

### (4) 진화 알고리즘 (Evolutionary Algorithm)

* 유전 알고리즘, 강화학습 기반 탐색.
* Google AutoML 등에서 사용.

---

### (5) Hyperband (조기 종료 기반 탐색)

* 성능이 나쁜 후보는 학습을 빨리 중단하고, 유망한 후보만 더 학습.
* 효율적으로 자원 사용.

---

## 4. 예시 (Python)

```python
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC

# 모델 정의
model = SVC()

# 하이퍼파라미터 후보
params = {
    "C": [0.1, 1, 10],
    "kernel": ["linear", "rbf"],
    "gamma": [0.1, 0.01, 0.001]
}

# Grid Search
grid = GridSearchCV(model, params, cv=3)
grid.fit(X_train, y_train)

print("최적 파라미터:", grid.best_params_)
print("최적 성능:", grid.best_score_)
```

---

## 5. 시험 포인트

* 하이퍼파라미터 = **학습 전에 정하는 값** (Weight/Bias는 학습 중 자동 학습).
* Grid Search vs Random Search vs Bayesian Optimization 차이.
* 잘못된 설명 유형 출제 가능:

  * ❌ “하이퍼파라미터는 학습 중 자동 조정되는 값이다.” (→ 오답)
  * ✅ “하이퍼파라미터 튜닝은 과적합/언더피팅 방지에 도움된다.” (→ 정답)
* 파일럿 문항 16: Bayesian 탐색 개념, Grid vs Random 비교 문제 출제됨.

---

✅ 정리:
하이퍼파라미터는 **학습 전 사람이 정하는 값**이고, **모델 성능에 큰 영향을 주므로 최적화가 필수**입니다.
시험에서는 “하이퍼파라미터 정의/예시/탐색 방법 비교”가 자주 출제됩니다.

---

👉 혹시 제가 이걸 기반으로 **하이퍼파라미터 관련 예상 문제 5\~10문항**을 만들어드릴까요?
