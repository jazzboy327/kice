좋습니다 👍
클래스 불균형(Class Imbalance)은 시험에서도 자주 출제되는 영역이고, 실제 산업에서도 중요한 이슈예요.
이번에는 **정의 → 문제점 → 해결 방법(각 기법별 상세 설명 + 용어 의미 + 예시 코드/적용 분야)** 순으로 정리해드리겠습니다.

---

# 📘 모델 튜닝 (클래스 불균형 문제)

---

## 1. 클래스 불균형 문제란?

* **정의**: 데이터에서 특정 클래스(Positive)가 극도로 적고, 다른 클래스(Negative)가 압도적으로 많은 상황.
* **예시**:

  * 스팸 메일 분류 → 정상 메일 99%, 스팸 1%
  * 의료 진단 → 정상 환자 98%, 질병 환자 2%
  * 제조업 불량품 탐지 → 정상 제품 99.9%, 불량품 0.1%

---

## 2. 문제점

* 모델이 대부분 \*\*다수 클래스(majority class)\*\*만 예측해도 높은 정확도(Accuracy)를 얻음.

  * 예: 스팸 1%, 정상 99% 데이터 → 모든 메일을 “정상”이라 예측해도 정확도 99%
  * 하지만 Recall(재현율)은 0 → 스팸 탐지 불가능.

👉 따라서, 클래스 불균형 문제에서는 Accuracy가 아닌 **Precision, Recall, F1-score** 등 다른 지표를 중시해야 함.

---

## 3. 해결 방법 (기법별 상세 설명)

---

### (1) 오버샘플링 (Over-sampling)

* **정의**: 소수 클래스(Positive) 데이터를 늘려서 비율을 맞춤.

#### ① 단순 복제 (Random Over-Sampling)

* 소수 클래스 샘플을 **중복 복사**.
* 장점: 간단함.
* 단점: 중복으로 인해 과적합 위험.

#### ② SMOTE (Synthetic Minority Oversampling Technique)

* 소수 클래스 샘플을 단순 복사하지 않고, \*\*주변 데이터와 보간(interpolation)\*\*하여 새로운 가짜 샘플 생성.
* 의미: 더 “부드러운” 데이터 분포 형성.
* 단점: 이상치(Outlier) 주변에서 샘플이 생성되면 성능 저하 가능.

```python
from imblearn.over_sampling import SMOTE
X_resampled, y_resampled = SMOTE().fit_resample(X, y)
```

#### ③ ADASYN (Adaptive Synthetic Sampling)

* SMOTE의 확장판.
* 소수 클래스 중에서도 \*\*더 학습하기 어려운 샘플(경계선 근처)\*\*을 중심으로 합성 데이터를 많이 생성.
* 장점: 데이터 분포를 더 균형 있게 만듦.

---

### (2) 언더샘플링 (Under-sampling)

* **정의**: 다수 클래스(Negative)를 줄여서 소수 클래스와 균형 맞춤.
* 장점: 학습 속도 ↑, 데이터 크기 감소.
* 단점: 정보 손실 위험 (많은 데이터 버려야 함).

#### 기법

* **Random Under-Sampling**: 무작위로 다수 클래스 샘플 제거.
* **NearMiss**: 소수 클래스와 가까운 다수 클래스 샘플만 선택.

```python
from imblearn.under_sampling import RandomUnderSampler
X_resampled, y_resampled = RandomUnderSampler().fit_resample(X, y)
```

---

### (3) 가중치 조정 (Class Weighting)

* **정의**: 모델 학습 시 손실 함수에서 소수 클래스에 더 큰 가중치(weight)를 줌.
* 장점: 데이터 증강 없이도 불균형 문제 완화.
* 예시: Scikit-learn의 `class_weight` 옵션.

```python
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(class_weight='balanced')  # 자동으로 반비례 가중치 부여
```

* 원리: 소수 클래스 오류 1개는 다수 클래스 오류 10개와 비슷한 패널티를 주도록 가중치 조정.

---

### (4) Focal Loss

* **정의**: 손실 함수에서 **쉽게 맞추는 샘플**은 가중치를 줄이고, **어려운 샘플**은 가중치를 크게 줘서 학습 집중.
* 원래는 \*\*Object Detection (RetinaNet)\*\*에서 제안된 방법.
* 장점: 극단적인 클래스 불균형 상황에서도 효과적.

#### 수식

$$
FL(p_t) = -(1 - p_t)^\gamma \cdot \log(p_t)
$$

* $p_t$: 예측 확률
* $\gamma$: 조정 파라미터 (일반적으로 2)
* 의미: 모델이 쉽게 맞추는 샘플은 (1-pt)^γ → 가중치 ↓,
  어려운 샘플은 가중치 ↑.

---

### (5) 데이터 증강 (Augmentation) – 이미지/텍스트

* 불균형 문제에서 Positive 데이터만 **증강**.
* 이미지: 회전, 반전, 노이즈 추가.
* 텍스트: 역번역(Back Translation), 동의어 치환.

---

### (6) 앙상블 기법

* 여러 모델을 학습시켜 **소수 클래스 예측력**을 강화.
* 예: Balanced Random Forest, EasyEnsemble.

---

## 4. 적용 분야 예시

* **의료**: 암 진단 → Positive(암 환자)가 극소수 → Recall 극대화 필요.
* **자율주행**: 보행자 vs 도로 → 보행자(Positive) 샘플 적음.
* **보안**: 이상 거래 탐지 → 대부분 정상, 소수만 이상 거래.

---

## 5. 시험 포인트 (파일럿 문항 15)

* 문제: 불량품 분류 (Positive=불량품 데이터가 0건으로 분류)
* 해결책:

  * 오버샘플링(SMOTE)
  * 언더샘플링
  * Focal Loss
  * 가중치 조정
* 오답 유도: “소수 클래스(Positive)에 낮은 가중치를 부여” → ❌

---

## ✅ 정리

| 기법         | 의미               | 장점       | 단점         | 시험 키워드        |
| ---------- | ---------------- | -------- | ---------- | ------------- |
| 오버샘플링      | 소수 클래스 샘플 늘리기    | 데이터 균형 ↑ | 과적합 위험     | SMOTE, ADASYN |
| 언더샘플링      | 다수 클래스 줄이기       | 학습 속도 ↑  | 데이터 손실     | NearMiss      |
| 가중치 조정     | 손실 함수에 가중치 부여    | 데이터 유지   | 조정이 민감     | class\_weight |
| Focal Loss | 어려운 샘플에 집중       | 불균형에 강함  | 하이퍼파라미터 필요 | RetinaNet     |
| 증강         | Positive만 데이터 확장 | 일반화 ↑    | 구현 필요      | Augmentation  |
| 앙상블        | 여러 모델 조합         | 강건성 ↑    | 복잡도 ↑      | EasyEnsemble  |

---

👉 이렇게 정리하면, 시험에서 **클래스 불균형 문제 → 해결 방법 4\~5가지 나열/구분** 문제가 나와도 대응할 수 있습니다.

혹시 원하시면 제가 이 주제로 **예상 객관식 문제 + 단답형 문제 세트**를 만들어드릴까요?
