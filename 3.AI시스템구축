좋습니다 👍 이번에는 **3번 챕터: AI 시스템 구축**을 **기본 개념 → 상세 설명 → 예시/코드 → 시험 포인트** 순서로 정리해드리겠습니다.

---

# 📘 3. AI 시스템 구축 (AI System Deployment & Operations)

AI 모델은 개발이 끝난 뒤 실제 환경에서 서비스할 수 있어야 합니다.
이를 위해 **배포(deployment)·모니터링·자동화·최적화** 과정이 필요합니다.
시험 범위에서는 **배포 방식, MLOps, 시스템 최적화**가 핵심입니다.

---

## 3-1. AI 시스템 설계 및 배포

### (1) Model-in-Service

* **정의**: 모델을 웹 서비스 내부에 포함시켜 배포하는 방식.
* **특징**

  * 웹 서버 코드 + 모델이 하나의 패키지.
  * 기존 인프라 활용 가능 (서버 확장 불필요).
  * 단점: 서버 자원을 많이 소모, 확장성 낮음.

**예시**

* Flask/Django 웹 서비스에 모델을 직접 포함.

```python
from flask import Flask, request
import joblib

app = Flask(__name__)
model = joblib.load("model.pkl")

@app.route("/predict", methods=["POST"])
def predict():
    data = request.json
    result = model.predict([data["features"]])
    return {"prediction": result.tolist()}
```

---

### (2) Model-as-Service

* **정의**: 모델을 웹 서비스와 분리해 독립적인 서비스로 배포.
* **특징**

  * 모델 서버와 웹 서버를 분리. (예: REST API, gRPC)
  * 확장성 높음 → 모델 서버만 스케일링 가능.
  * 단점: 네트워크 지연(latency) 발생 가능.

**예시**

* FastAPI 모델 서버 + Nginx API Gateway

```python
from fastapi import FastAPI
import joblib

app = FastAPI()
model = joblib.load("model.pkl")

@app.post("/predict")
def predict(features: list[float]):
    return {"prediction": model.predict([features]).tolist()}
```

---

**시험 포인트 (파일럿 문항 17)**

* Model-in-service → 인프라 재사용 가능, 확장성 ↓
* Model-as-service → 확장성 ↑, latency ↑

---

## 3-2. AI 시스템 모니터링 및 자동화 (MLOps)

### (1) MLOps란?

* **Machine Learning + DevOps**
* 모델의 **개발-배포-운영** 전 과정을 자동화/관리하는 프로세스.

---

### (2) MLOps 수준 (Level)

1. **Level 0 (Manual Process)**

   * 수동 실행: 데이터 준비, 학습, 배포 모두 사람이 직접 수행.
   * 문제: 재현성 ↓, 반복 작업 많음.

2. **Level 1 (ML Pipeline Automation)**

   * 데이터 수집 → 전처리 → 학습 → 배포 자동화.
   * 예: Airflow, Kubeflow Pipeline.

3. **Level 2 (CI/CD for ML)**

   * 코드 업데이트 시 자동으로 데이터 학습, 모델 평가, 배포.
   * 모니터링 & 드리프트 감지 포함.

---

### (3) 주요 개념

* **Training-Serving Skew**

  * 학습 환경과 실제 서비스 환경 차이로 성능 저하 발생.
  * 예: 학습 시 정규화 했는데, 서빙 시 정규화 미적용.
  * 해결: Feature Store, 파이프라인 일관성 유지.

* **데이터 드리프트 (Data Drift)**

  * 실제 데이터 분포가 학습 데이터와 달라짐.
  * 예: 사용자 행동 패턴 변화.

* **모델 드리프트 (Model Drift)**

  * 모델 성능이 시간이 지나며 떨어짐.
  * 예: 스팸 메일 필터가 새로운 유형의 스팸을 못 잡음.

---

**시험 포인트 (파일럿 문항 24)**

* Level 0: 수동.
* Level 1: 자동화된 ML 파이프라인.
* Training-serving skew는 오프라인 학습만으로 해결 불가.
* Level 1 이상에서는 모니터링으로 성능 저하 감지 가능.

---

## 3-3. AI 시스템 최적화

### (1) 최적화 필요성

* 대형 모델은 자원 소모 ↑ → 실제 서비스에서 속도와 비용 문제.
* 최적화를 통해 **속도 ↑, 메모리 ↓, 정확도 유지** 목표.

---

### (2) 주요 기법

1. **Pruning (가지치기)**

   * 불필요한 weight, neuron 제거.
   * FLOPs 감소 → 실행 속도 ↑.

2. **Quantization (양자화)**

   * 모델 파라미터를 저정밀도로 변환. (FP32 → INT8)
   * 메모리 절감, 실행 속도 향상.

3. **Knowledge Distillation (지식 증류)**

   * 큰 Teacher 모델 → 작은 Student 모델에 지식 전달.
   * Student 모델은 가볍지만 Teacher 성능에 근접.

4. **ONNX, TensorRT 변환**

   * 모델을 최적화된 형식으로 변환해 GPU에서 빠르게 실행.

5. **EfficientNet (Compound Scaling)**

   * 깊이·너비·해상도를 균형 있게 조절해 효율 극대화.

---

**시험 포인트 (파일럿 문항 18 & 23)**

* 문항 18: AI 배포 프로세스 (전처리 → 학습 → 패키징).
* 문항 23: FLOPs 성능 최적화 (Pruning, Compound Scaling).

---

## 정리

| 영역       | 주요 개념                        | 키워드                                       |
| -------- | ---------------------------- | ----------------------------------------- |
| 설계/배포    | Model-in vs Model-as Service | 확장성, 인프라 활용                               |
| 모니터링/자동화 | MLOps Level 0\~2             | Training-serving skew, Drift              |
| 최적화      | 모델 경량화                       | Pruning, Quantization, Distillation, ONNX |

---

✅ 여기까지가 챕터 3 (AI 시스템 구축)의 상세 설명입니다.

👉 이제 마지막 \*\*챕터 4 (AI 트렌드)\*\*도 같은 방식으로 풀어드릴까요?
