좋은 질문이에요 👍
데이터 수집은 모델 성능에 직접적인 영향을 주기 때문에 **편향·대표성·불균형** 외에도 더 고려할 사항과 수집 기법들이 있습니다.

---

## 📌 데이터 수집 시 추가 고려 사항

### 1. **데이터 품질(Quality)**

* **정확성(Accuracy)**: 데이터가 사실과 일치해야 함.

  * 예: 온도 센서 값이 실제와 다르면 모델이 잘못 학습.
* **일관성(Consistency)**: 서로 다른 출처 데이터 간에 형식, 단위가 일치해야 함.

  * 예: 어떤 데이터는 °C, 다른 데이터는 °F → 변환 필요.

---

### 2. **데이터 양(Quantity)**

* 딥러닝은 대량의 데이터가 필요.
* 데이터가 부족하면 → 증강(Augmentation) or 합성(Synthetic Data) 필요.

---

### 3. **데이터 다양성(Diversity)**

* 다양한 상황/조건 포함해야 함.
* 자율주행 예시: 낮/밤, 맑음/비/눈, 시골/도시 등.
* 의료 예시: 성별, 나이, 인종 다양성.

---

### 4. **데이터 최신성(Freshness, Timeliness)**

* 오래된 데이터는 실제 상황과 맞지 않을 수 있음.
* 금융/소셜 데이터는 “실시간성”이 중요.

---

### 5. **데이터 보안 및 프라이버시(Privacy)**

* 개인정보 포함 시 → 익명화/비식별화 필요.
* 관련 법규 준수 (예: GDPR, 개인정보 보호법).

---

### 6. **데이터 비용(Cost)**

* 크롤링 데이터는 무료일 수 있지만, 의료 데이터·교통 데이터는 비용 발생.
* 수집 비용 대비 효과 고려.

---

## 📌 데이터 수집 기법 (Techniques)

1. **수동 수집 (Manual Collection)**

   * 직접 기록, 실험, 설문.
   * 정확성은 높지만, 비용/시간 많이 듦.

2. **센서/IoT 기반 수집**

   * 카메라, LiDAR, GPS, 온도/습도 센서.
   * 자율주행, 스마트시티, 헬스케어 분야에서 활용.

3. **로그(Log) 데이터 수집**

   * 서비스 이용 기록 (웹 클릭 로그, 거래 로그).
   * 대량/실시간 수집 가능.

4. **웹 크롤링(Web Crawling)**

   * 오픈 데이터나 웹사이트에서 자동 수집.
   * 예: 뉴스 기사 크롤링으로 텍스트 데이터 확보.

5. **API 활용**

   * Twitter API, OpenWeather API, 금융 API 등.
   * 구조화된 데이터 수집에 용이.

6. **크라우드소싱(Crowdsourcing)**

   * Amazon Mechanical Turk, 크라우드웍스 같은 플랫폼에서 다수 인력이 라벨링/데이터 생성.

7. **합성 데이터(Synthetic Data)**

   * 시뮬레이션(게임 엔진, Unity, CARLA), GAN, Diffusion Model로 가짜 데이터 생성.
   * 희귀 상황(예: 교통사고 장면) 재현에 유용.

8. **데이터 공유/오픈 데이터셋 활용**

   * ImageNet, COCO, Kaggle Dataset, 공공데이터포털 등.

---

## 📌 시험 포인트 (추가 예상)

* 데이터 수집 시 **대표성/다양성/편향 최소화**가 가장 중요.
* 프라이버시/윤리 이슈도 출제될 가능성 있음.
* **수집 기법**은 “크롤링, 센서, 합성 데이터” 같은 구체적인 방법을 물을 수 있음.

---

👉 정리하면, 데이터 수집에서 **편향/대표성/불균형 + 품질/다양성/최신성/보안/비용**까지 고려해야 하고,
기법으로는 **센서·로그·크롤링·API·크라우드소싱·합성 데이터**가 대표적이에요.

---

혹시 원하시면 제가 이 부분을 시험 대비용으로 **예상 문제(객관식 + 단답식)** 형태로 만들어드릴까요?
